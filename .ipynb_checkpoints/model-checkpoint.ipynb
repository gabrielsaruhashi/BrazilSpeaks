{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest.pickle         model.ipynb\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                 model_plot.png\r\n",
      "analysis.Rmd                \u001b[34mmodels\u001b[m\u001b[m\r\n",
      "analysis.pdf                out\r\n",
      "\u001b[34manalysis_files\u001b[m\u001b[m              \u001b[31mplaylist_processor.py\u001b[m\u001b[m\r\n",
      "analysis_final.Rmd          \u001b[34mplots\u001b[m\u001b[m\r\n",
      "brew                        protest.csv\r\n",
      "brz_dictatorship.csv        pt_stopwords.txt\r\n",
      "brz_dictatorship_target.csv sequences.txt\r\n",
      "danceability.jpeg           speechiness_bp.jpeg\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                        valence_bp.jpeg\r\n",
      "energy.jpeg                 visuals.py\r\n",
      "influence.py                whosampled_clean_songs.csv\r\n",
      "jovem_guarda.csv            whosampled_data.csv\r\n",
      "lstm_char_model.ipynb       whosampled_list.csv\r\n",
      "main.pyc                    whosampled_scraper.py\r\n",
      "model.h5                    wordmodel.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>song_sp_uri</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_isrc</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>song_lyrics</th>\n",
       "      <th>class</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>id</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_photo</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>artist_sp_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:4zJnSZJjCmGnkQX1W38ZIl</td>\n",
       "      <td>Calix-Se</td>\n",
       "      <td>US7VG1593526</td>\n",
       "      <td>36</td>\n",
       "      <td>pai sinto falta voce aqui rua campim quanto to...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.744</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812</td>\n",
       "      <td>82.004</td>\n",
       "      <td>4zJnSZJjCmGnkQX1W38ZIl</td>\n",
       "      <td>360751</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "      <td>Trilha Sonora do Gueto</td>\n",
       "      <td>https://i.scdn.co/image/f44f9e10538aa6391688ca...</td>\n",
       "      <td>45</td>\n",
       "      <td>130298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spotify:track:744T5MTpQJhem1FPdKvTQ1</td>\n",
       "      <td>Direita Vou Ver</td>\n",
       "      <td>BXRCL1800064</td>\n",
       "      <td>25</td>\n",
       "      <td>`` continuo sendo socialista , portanto , esqu...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.811</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>79.934</td>\n",
       "      <td>744T5MTpQJhem1FPdKvTQ1</td>\n",
       "      <td>364504</td>\n",
       "      <td>4</td>\n",
       "      <td>adoracao</td>\n",
       "      <td>Mensageiros da Profecia</td>\n",
       "      <td>https://i.scdn.co/image/688287e9b2eefe63a25912...</td>\n",
       "      <td>35</td>\n",
       "      <td>20698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:6Wt61AZLG0bN2KasopE2sj</td>\n",
       "      <td>Capítulo 4, Versículo 3</td>\n",
       "      <td>US7VG1324929</td>\n",
       "      <td>58</td>\n",
       "      <td>60 % jovens periferia antecedentes criminais j...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.515</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>87.841</td>\n",
       "      <td>6Wt61AZLG0bN2KasopE2sj</td>\n",
       "      <td>486560</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "      <td>Racionais MC's</td>\n",
       "      <td>https://i.scdn.co/image/0e9f58b86b301af364cc4c...</td>\n",
       "      <td>67</td>\n",
       "      <td>2495926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:4EBu1H5VUbBRXGtARMnkib</td>\n",
       "      <td>Brasil Com \"P\"</td>\n",
       "      <td>US7VG1539057</td>\n",
       "      <td>21</td>\n",
       "      <td>pesquisa publicada prova : preferencialmente p...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.486</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564</td>\n",
       "      <td>57.986</td>\n",
       "      <td>4EBu1H5VUbBRXGtARMnkib</td>\n",
       "      <td>104227</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "      <td>GOG</td>\n",
       "      <td>https://i.scdn.co/image/de0d09c17287d9656696bb...</td>\n",
       "      <td>42</td>\n",
       "      <td>47072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>spotify:track:58ZMFOd08nb2WrOoFhI4cY</td>\n",
       "      <td>Filho maravilha</td>\n",
       "      <td>BRWMB9801175</td>\n",
       "      <td>33</td>\n",
       "      <td>novamente chegou inspiracao amor , emocao , ex...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.865</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774</td>\n",
       "      <td>136.564</td>\n",
       "      <td>58ZMFOd08nb2WrOoFhI4cY</td>\n",
       "      <td>215693</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Jorge Ben Jor</td>\n",
       "      <td>https://i.scdn.co/image/a9c6a324c5f4a0f25bc711...</td>\n",
       "      <td>64</td>\n",
       "      <td>368372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           song_sp_uri                song_name  \\\n",
       "1           1  spotify:track:4zJnSZJjCmGnkQX1W38ZIl                 Calix-Se   \n",
       "2           2  spotify:track:744T5MTpQJhem1FPdKvTQ1          Direita Vou Ver   \n",
       "3           3  spotify:track:6Wt61AZLG0bN2KasopE2sj  Capítulo 4, Versículo 3   \n",
       "4           4  spotify:track:4EBu1H5VUbBRXGtARMnkib           Brasil Com \"P\"   \n",
       "5           5  spotify:track:58ZMFOd08nb2WrOoFhI4cY          Filho maravilha   \n",
       "\n",
       "      song_isrc  song_popularity  \\\n",
       "1  US7VG1593526               36   \n",
       "2  BXRCL1800064               25   \n",
       "3  US7VG1324929               58   \n",
       "4  US7VG1539057               21   \n",
       "5  BRWMB9801175               33   \n",
       "\n",
       "                                         song_lyrics    class  danceability  \\\n",
       "1  pai sinto falta voce aqui rua campim quanto to...  Protest         0.760   \n",
       "2  `` continuo sendo socialista , portanto , esqu...  Protest         0.545   \n",
       "3  60 % jovens periferia antecedentes criminais j...  Protest         0.625   \n",
       "4  pesquisa publicada prova : preferencialmente p...  Protest         0.628   \n",
       "5  novamente chegou inspiracao amor , emocao , ex...  Protest         0.561   \n",
       "\n",
       "   energy  key         ...           valence    tempo                      id  \\\n",
       "1   0.744   11         ...             0.812   82.004  4zJnSZJjCmGnkQX1W38ZIl   \n",
       "2   0.811   11         ...             0.639   79.934  744T5MTpQJhem1FPdKvTQ1   \n",
       "3   0.515    8         ...             0.903   87.841  6Wt61AZLG0bN2KasopE2sj   \n",
       "4   0.486    8         ...             0.564   57.986  4EBu1H5VUbBRXGtARMnkib   \n",
       "5   0.865    4         ...             0.774  136.564  58ZMFOd08nb2WrOoFhI4cY   \n",
       "\n",
       "   duration_ms  time_signature      artist_genres              artist_name  \\\n",
       "1       360751               4  brazilian hip hop   Trilha Sonora do Gueto   \n",
       "2       364504               4           adoracao  Mensageiros da Profecia   \n",
       "3       486560               4  brazilian hip hop           Racionais MC's   \n",
       "4       104227               4  brazilian hip hop                      GOG   \n",
       "5       215693               4         bossa nova            Jorge Ben Jor   \n",
       "\n",
       "                                        artist_photo artist_popularity  \\\n",
       "1  https://i.scdn.co/image/f44f9e10538aa6391688ca...                45   \n",
       "2  https://i.scdn.co/image/688287e9b2eefe63a25912...                35   \n",
       "3  https://i.scdn.co/image/0e9f58b86b301af364cc4c...                67   \n",
       "4  https://i.scdn.co/image/de0d09c17287d9656696bb...                42   \n",
       "5  https://i.scdn.co/image/a9c6a324c5f4a0f25bc711...                64   \n",
       "\n",
       "   artist_sp_followers  \n",
       "1               130298  \n",
       "2                20698  \n",
       "3              2495926  \n",
       "4                47072  \n",
       "5               368372  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('brz_dictatorship.csv', encoding='utf-8')\n",
    "df_test = pd.read_csv('whosampled_data.csv', encoding='utf-8').dropna(axis=0)\n",
    "df = df.dropna(axis=0)\n",
    "display(df_test.head())\n",
    "\n",
    "stopwords = open(\"pt_stopwords.txt\").readlines()\n",
    "stopwords = list(map(str.strip, stopwords))\n",
    "\n",
    "df['tempo'] = pd.to_numeric(df['tempo'], downcast=\"float\")\n",
    "df['duration_ms'] = pd.to_numeric(df['duration_ms'], downcast=\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = RSLPStemmer()\n",
    "df['cleaned'] = df['song_lyrics'].astype('str')\n",
    "df['cleaned'] = df['cleaned'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 1391)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=stopwords, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(df['cleaned']).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key]\n",
    "\n",
    "class NumSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                           song_sp_uri         song_name  \\\n",
      "0           0  spotify:track:0VUgbCK0k8QWGpLiEV8YYZ            Cálice   \n",
      "1           1  spotify:track:2GAFZG9Z7UGS1iMm4Idrnr    Apesar De Você   \n",
      "2           2  spotify:track:06ND7qqsmIRCuWdQNQIlTE         Roda-Viva   \n",
      "3           3  spotify:track:3Ig3k8enaBZy7cohqfnWVz  Como nossos pais   \n",
      "4           4  spotify:track:3AQg8DR76bH9Ko3mZXuSWK     Mosca Na Sopa   \n",
      "\n",
      "      song_isrc  song_popularity  \\\n",
      "0  BRPGD7800015               50   \n",
      "1  BRPGD7800024               57   \n",
      "2  BRSGL6800006               53   \n",
      "3  BRWMB9705419               27   \n",
      "4  BRMCA7300117               45   \n",
      "\n",
      "                                         song_lyrics    class  danceability  \\\n",
      "0  pai , afasta mim calice pai , afasta mim calic...  Protest         0.596   \n",
      "1  amanha vai outro dia amanha vai outro dia aman...  Protest         0.568   \n",
      "2  dias gente sente partiu morreu gente estancou ...  Protest         0.502   \n",
      "3  nao quero falar grande amor coisas aprendi dis...  Protest         0.463   \n",
      "4  mosca pousou sopa mosca pintou pra abusar mosc...  Protest         0.609   \n",
      "\n",
      "   energy  key                        ...                               tempo  \\\n",
      "0   0.372    4                        ...                          123.125000   \n",
      "1   0.574    4                        ...                          107.820000   \n",
      "2   0.512   10                        ...                          133.173996   \n",
      "3   0.337    8                        ...                           96.558998   \n",
      "4   0.760    2                        ...                           92.022003   \n",
      "\n",
      "                       id  duration_ms  time_signature          artist_genres  \\\n",
      "0  0VUgbCK0k8QWGpLiEV8YYZ     241867.0               4             bossa nova   \n",
      "1  2GAFZG9Z7UGS1iMm4Idrnr     235547.0               4             bossa nova   \n",
      "2  06ND7qqsmIRCuWdQNQIlTE     233400.0               4             bossa nova   \n",
      "3  3Ig3k8enaBZy7cohqfnWVz     280627.0               4             bossa nova   \n",
      "4  3AQg8DR76bH9Ko3mZXuSWK     239187.0               4  brazilian psychedelic   \n",
      "\n",
      "     artist_name                                       artist_photo  \\\n",
      "0  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "1  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "2  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "3       Belchior  https://i.scdn.co/image/22365c7789eb990937bb71...   \n",
      "4    Raul Seixas  https://i.scdn.co/image/ad67b61dd80b071a2ac908...   \n",
      "\n",
      "   artist_popularity artist_sp_followers  \\\n",
      "0                 63              542214   \n",
      "1                 63              542214   \n",
      "2                 63              542214   \n",
      "3                 57              299597   \n",
      "4                 63              829961   \n",
      "\n",
      "                                             cleaned  \n",
      "0  pai afast mim calic pai afast mim calic pai af...  \n",
      "1  amanh vai outr dia amanh vai outr dia amanh va...  \n",
      "2  dia gent sent part morr gent estanc repent mun...  \n",
      "3  nao quer fal grand am cois aprend disc quer co...  \n",
      "4  mosc pous sop mosc pint pra abus mosc pous sop...  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                  score\n",
      "-------------------  -------\n",
      "bern_nb               0.5862\n",
      "bern_nb_tfidf         0.5862\n",
      "mult_nb               0.6362\n",
      "mult_nb_tfidf         0.5542\n",
      "random_forest         0.6725\n",
      "random_forest_tfidf   0.7755\n",
      "svc                   0.6672\n",
      "svc_tfidf             0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "y = df['class']\n",
    "\n",
    "labels = df['class'].map(lambda x : 1 if x == 'Protest' else 0)\n",
    "\n",
    "\n",
    "# train word to vector on texts \n",
    "model = Word2Vec(X['song_lyrics'], size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}\n",
    "\n",
    "\n",
    "# ('lyrics', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='song_lyrics')),\n",
    "#                 ('tfidf', vectorizer),\n",
    "#             ])),\n",
    "\n",
    "# multiple machine learning models\n",
    "mult_nb = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), \n",
    "                (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                    ])),\n",
    "                    (\"bernoulli nb\", BernoulliNB())])\n",
    "\n",
    "mult_nb_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), \n",
    "                          (\"multinomial nb\", MultinomialNB())])\n",
    "\n",
    "bern_nb_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM \n",
    "svc = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                ])),\n",
    "                (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "svc_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "# Random Forest\n",
    "random_forest_tfidf = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "#             Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "            ])),\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.values())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.sum([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.values())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "    (\"bern_nb\", bern_nb),\n",
    "    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"random_forest\", random_forest),\n",
    "    (\"random_forest_tfidf\", random_forest_tfidf),\n",
    "#     (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]\n",
    "\n",
    "## Comparing different models\n",
    "scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n",
    "                 for name, model in all_models])\n",
    "print(tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2152ac88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(x=[name for name, _ in scores], y=[score for _, score in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def benchmark(model, X, y, n):\n",
    "    test_size = 1 - (n / float(len(y)))\n",
    "    scores = []\n",
    "    #sss =  StratifiedShuffleSplit(n_splits=5, test_size=test_size)\n",
    "    for train, test in sss(y):\n",
    "        X_train, X_test = X[train], X[test]\n",
    "        y_train, y_test = y[train], y[test]\n",
    "        scores.append(accuracy_score(model.fit(X_train, y_train).predict(X_test), y_test))\n",
    "    return np.mean(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'StratifiedShuffleSplit' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-49603cec4a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         table.append({'model': name, \n\u001b[0;32m----> 6\u001b[0;31m                       \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                       'train_size': n})\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-1cf80dff7152>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(model, X, y, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'StratifiedShuffleSplit' object is not callable"
     ]
    }
   ],
   "source": [
    "train_sizes = [10, 25, 50, 80, 120]\n",
    "table = []\n",
    "for name, model in all_models:\n",
    "    for n in train_sizes:\n",
    "        table.append({'model': name, \n",
    "                      'accuracy': benchmark(model, X, y, n), \n",
    "                      'train_size': n})\n",
    "df = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-079c9ecfd9cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fig = sns.pointplot(x='train_size', y='accuracy', hue='model', \n\u001b[0;32m----> 3\u001b[0;31m                     data=df[df.model.map(lambda x: x in [\"mult_nb\", \"svc_tfidf\", \"w2v_tfidf\", \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                          \u001b[0;34m\"glove_small_tfidf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"glove_big_tfidf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                         ])])\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'model'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "fig = sns.pointplot(x='train_size', y='accuracy', hue='model', \n",
    "                    data=df[df.model.map(lambda x: x in [\"mult_nb\", \"svc_tfidf\", \"w2v_tfidf\", \n",
    "                                                         \"glove_small_tfidf\", \"glove_big_tfidf\", \n",
    "                                                        ])])\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "fig.set(ylabel=\"accuracy\")\n",
    "fig.set(xlabel=\"labeled training examples\")\n",
    "fig.set(title=\"R8 benchmark\")\n",
    "fig.set(ylabel=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# this block is to split the dataset into training and testing set \n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "Y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "# with open('RandomForest.pickle', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))\n",
    "\n",
    "forest = pipeline.steps[1][1]\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "print(len(df_test))\n",
    "print(df_test[['song_name', 'artist_name', 'artist_photo']])\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "target_vocab = list(df['song_lyrics'].str.split(' ', expand=True).stack().unique())\n",
    "vocabulary_size = len(target_vocab)\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['song_lyrics'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['song_lyrics'])\n",
    "\n",
    "maxlen = df['song_lyrics'].str.len().max()\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryClassificationConvModel():\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(Embedding(vocabulary_size, 50, input_length=maxlen, trainable=False))\n",
    "    model_conv.add(Dropout(0.2))\n",
    "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(LSTM(50))\n",
    "    model_conv.add(Dense(1, activation='sigmoid'))\n",
    "    model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "model_conv = BinaryClassificationConvModel()\n",
    "model_conv.fit(X_train, np.array(y_train), epochs = 50,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
