{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest.pickle         main.pyc\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                 model.ipynb\r\n",
      "analysis.Rmd                \u001b[31mplaylist_processor.py\u001b[m\u001b[m\r\n",
      "analysis.pdf                protest.csv\r\n",
      "\u001b[34manalysis_files\u001b[m\u001b[m              pt_stopwords.txt\r\n",
      "brz_dictatorship.csv        visuals.py\r\n",
      "brz_dictatorship_target.csv whosampled_scraper.py\r\n",
      "jovem_guarda.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>song_sp_uri</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_isrc</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>song_lyrics</th>\n",
       "      <th>class</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>id</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_photo</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>artist_sp_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0VUgbCK0k8QWGpLiEV8YYZ</td>\n",
       "      <td>Cálice</td>\n",
       "      <td>BRPGD7800015</td>\n",
       "      <td>50</td>\n",
       "      <td>pai , afasta mim calice pai , afasta mim calic...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293</td>\n",
       "      <td>123.125</td>\n",
       "      <td>0VUgbCK0k8QWGpLiEV8YYZ</td>\n",
       "      <td>241867</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Chico Buarque</td>\n",
       "      <td>https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...</td>\n",
       "      <td>63</td>\n",
       "      <td>542214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:2GAFZG9Z7UGS1iMm4Idrnr</td>\n",
       "      <td>Apesar De Você</td>\n",
       "      <td>BRPGD7800024</td>\n",
       "      <td>57</td>\n",
       "      <td>amanha vai outro dia amanha vai outro dia aman...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.574</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680</td>\n",
       "      <td>107.820</td>\n",
       "      <td>2GAFZG9Z7UGS1iMm4Idrnr</td>\n",
       "      <td>235547</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Chico Buarque</td>\n",
       "      <td>https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...</td>\n",
       "      <td>63</td>\n",
       "      <td>542214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spotify:track:06ND7qqsmIRCuWdQNQIlTE</td>\n",
       "      <td>Roda-Viva</td>\n",
       "      <td>BRSGL6800006</td>\n",
       "      <td>53</td>\n",
       "      <td>dias gente sente partiu morreu gente estancou ...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.512</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651</td>\n",
       "      <td>133.174</td>\n",
       "      <td>06ND7qqsmIRCuWdQNQIlTE</td>\n",
       "      <td>233400</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Chico Buarque</td>\n",
       "      <td>https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...</td>\n",
       "      <td>63</td>\n",
       "      <td>542214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:3Ig3k8enaBZy7cohqfnWVz</td>\n",
       "      <td>Como nossos pais</td>\n",
       "      <td>BRWMB9705419</td>\n",
       "      <td>27</td>\n",
       "      <td>nao quero falar grande amor coisas aprendi dis...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.337</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>96.559</td>\n",
       "      <td>3Ig3k8enaBZy7cohqfnWVz</td>\n",
       "      <td>280627</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Belchior</td>\n",
       "      <td>https://i.scdn.co/image/22365c7789eb990937bb71...</td>\n",
       "      <td>57</td>\n",
       "      <td>299597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:3AQg8DR76bH9Ko3mZXuSWK</td>\n",
       "      <td>Mosca Na Sopa</td>\n",
       "      <td>BRMCA7300117</td>\n",
       "      <td>45</td>\n",
       "      <td>mosca pousou sopa mosca pintou pra abusar mosc...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>92.022</td>\n",
       "      <td>3AQg8DR76bH9Ko3mZXuSWK</td>\n",
       "      <td>239187</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian psychedelic</td>\n",
       "      <td>Raul Seixas</td>\n",
       "      <td>https://i.scdn.co/image/ad67b61dd80b071a2ac908...</td>\n",
       "      <td>63</td>\n",
       "      <td>829961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           song_sp_uri         song_name  \\\n",
       "0           0  spotify:track:0VUgbCK0k8QWGpLiEV8YYZ            Cálice   \n",
       "1           1  spotify:track:2GAFZG9Z7UGS1iMm4Idrnr    Apesar De Você   \n",
       "2           2  spotify:track:06ND7qqsmIRCuWdQNQIlTE         Roda-Viva   \n",
       "3           3  spotify:track:3Ig3k8enaBZy7cohqfnWVz  Como nossos pais   \n",
       "4           4  spotify:track:3AQg8DR76bH9Ko3mZXuSWK     Mosca Na Sopa   \n",
       "\n",
       "      song_isrc  song_popularity  \\\n",
       "0  BRPGD7800015               50   \n",
       "1  BRPGD7800024               57   \n",
       "2  BRSGL6800006               53   \n",
       "3  BRWMB9705419               27   \n",
       "4  BRMCA7300117               45   \n",
       "\n",
       "                                         song_lyrics    class  danceability  \\\n",
       "0  pai , afasta mim calice pai , afasta mim calic...  Protest         0.596   \n",
       "1  amanha vai outro dia amanha vai outro dia aman...  Protest         0.568   \n",
       "2  dias gente sente partiu morreu gente estancou ...  Protest         0.502   \n",
       "3  nao quero falar grande amor coisas aprendi dis...  Protest         0.463   \n",
       "4  mosca pousou sopa mosca pintou pra abusar mosc...  Protest         0.609   \n",
       "\n",
       "   energy  key         ...           valence    tempo                      id  \\\n",
       "0   0.372    4         ...             0.293  123.125  0VUgbCK0k8QWGpLiEV8YYZ   \n",
       "1   0.574    4         ...             0.680  107.820  2GAFZG9Z7UGS1iMm4Idrnr   \n",
       "2   0.512   10         ...             0.651  133.174  06ND7qqsmIRCuWdQNQIlTE   \n",
       "3   0.337    8         ...             0.269   96.559  3Ig3k8enaBZy7cohqfnWVz   \n",
       "4   0.760    2         ...             0.880   92.022  3AQg8DR76bH9Ko3mZXuSWK   \n",
       "\n",
       "   duration_ms  time_signature          artist_genres    artist_name  \\\n",
       "0       241867               4             bossa nova  Chico Buarque   \n",
       "1       235547               4             bossa nova  Chico Buarque   \n",
       "2       233400               4             bossa nova  Chico Buarque   \n",
       "3       280627               4             bossa nova       Belchior   \n",
       "4       239187               4  brazilian psychedelic    Raul Seixas   \n",
       "\n",
       "                                        artist_photo artist_popularity  \\\n",
       "0  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...                63   \n",
       "1  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...                63   \n",
       "2  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...                63   \n",
       "3  https://i.scdn.co/image/22365c7789eb990937bb71...                57   \n",
       "4  https://i.scdn.co/image/ad67b61dd80b071a2ac908...                63   \n",
       "\n",
       "   artist_sp_followers  \n",
       "0               542214  \n",
       "1               542214  \n",
       "2               542214  \n",
       "3               299597  \n",
       "4               829961  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('brz_dictatorship.csv', encoding='utf-8')\n",
    "df = df.dropna(axis=0)\n",
    "display(df.head())\n",
    "\n",
    "stopwords = open(\"pt_stopwords.txt\").readlines()\n",
    "stopwords = list(map(str.strip, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = RSLPStemmer()\n",
    "df['cleaned'] = df['song_lyrics'].astype('str')\n",
    "df['cleaned'] = df['cleaned'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 1391)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=stopwords, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(df['cleaned']).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key]\n",
    "\n",
    "class NumSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: pandas in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (0.23.4)\n",
      "Requirement already satisfied: numpy in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (1.15.4)\n",
      "Requirement already satisfied: gensim in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (3.6.0)\n",
      "Requirement already satisfied: tabulate in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (0.8.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from sklearn) (0.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: requests in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: bz2file in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: boto3 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (1.9.80)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.80 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.80)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.80->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
     ]
    }
   ],
   "source": [
    "# install machine learning package\n",
    "import sys\n",
    "!{sys.executable} -m pip install sklearn pandas numpy gensim tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6, 146]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-af7d28a55dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m## Comparing different models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n\u001b[0;32m--> 102\u001b[0;31m                  for name, model in all_models])\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".4f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-af7d28a55dff>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m## Comparing different models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n\u001b[0;32m--> 102\u001b[0;31m                  for name, model in all_models])\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".4f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \"\"\"\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6, 146]"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "y = df['class']\n",
    "\n",
    "# train word to vector on texts \n",
    "model = Word2Vec(X['song_lyrics'], size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}\n",
    "\n",
    "\n",
    "('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "\n",
    "# multiple machine learning models\n",
    "mult_nb = Pipeline([('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "            ])), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "mult_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM \n",
    "svc = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.values())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.values())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "    (\"bern_nb\", bern_nb),\n",
    "    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"w2v\", etree_w2v),\n",
    "    (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]\n",
    "\n",
    "## Comparing different models\n",
    "scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n",
    "                 for name, model in all_models])\n",
    "print(tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Jovem Guarda       0.73      0.88      0.80        25\n",
      "     Protest       0.81      0.62      0.70        21\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        46\n",
      "   macro avg       0.77      0.75      0.75        46\n",
      "weighted avg       0.77      0.76      0.76        46\n",
      "\n",
      "[[22  3]\n",
      " [ 8 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# this block is to split the dataset into training and testing set \n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "Y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "# with open('RandomForest.pickle', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(net, criterion, optimizer, trainloader):\n",
    "    for epoch in range(2):\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(mnist_trainloader):\n",
    "#             images, labels = data\n",
    "            \n",
    "#             print(images.shape)\n",
    "            outputs = mnist_net.forward(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (batch_idx) % 2000 == 0:\n",
    "                print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, batch_idx, loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
