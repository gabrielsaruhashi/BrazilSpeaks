{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest.pickle         main.pyc\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                 model.ipynb\r\n",
      "analysis.Rmd                \u001b[34mmodels\u001b[m\u001b[m\r\n",
      "analysis.pdf                \u001b[31mplaylist_processor.py\u001b[m\u001b[m\r\n",
      "\u001b[34manalysis_files\u001b[m\u001b[m              protest.csv\r\n",
      "brz_dictatorship.csv        pt_stopwords.txt\r\n",
      "brz_dictatorship_target.csv visuals.py\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                        whosampled_scraper.py\r\n",
      "jovem_guarda.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>song_sp_uri</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_isrc</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>song_lyrics</th>\n",
       "      <th>class</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>id</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_photo</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>artist_sp_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0VUgbCK0k8QWGpLiEV8YYZ</td>\n",
       "      <td>Cálice</td>\n",
       "      <td>BRPGD7800015</td>\n",
       "      <td>50</td>\n",
       "      <td>pai , afasta mim calice pai , afasta mim calic...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293</td>\n",
       "      <td>123.125</td>\n",
       "      <td>0VUgbCK0k8QWGpLiEV8YYZ</td>\n",
       "      <td>241867</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Chico Buarque</td>\n",
       "      <td>https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...</td>\n",
       "      <td>63</td>\n",
       "      <td>542214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:2GAFZG9Z7UGS1iMm4Idrnr</td>\n",
       "      <td>Apesar De Você</td>\n",
       "      <td>BRPGD7800024</td>\n",
       "      <td>57</td>\n",
       "      <td>amanha vai outro dia amanha vai outro dia aman...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.574</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680</td>\n",
       "      <td>107.820</td>\n",
       "      <td>2GAFZG9Z7UGS1iMm4Idrnr</td>\n",
       "      <td>235547</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Chico Buarque</td>\n",
       "      <td>https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...</td>\n",
       "      <td>63</td>\n",
       "      <td>542214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spotify:track:06ND7qqsmIRCuWdQNQIlTE</td>\n",
       "      <td>Roda-Viva</td>\n",
       "      <td>BRSGL6800006</td>\n",
       "      <td>53</td>\n",
       "      <td>dias gente sente partiu morreu gente estancou ...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.512</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651</td>\n",
       "      <td>133.174</td>\n",
       "      <td>06ND7qqsmIRCuWdQNQIlTE</td>\n",
       "      <td>233400</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Chico Buarque</td>\n",
       "      <td>https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...</td>\n",
       "      <td>63</td>\n",
       "      <td>542214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:3Ig3k8enaBZy7cohqfnWVz</td>\n",
       "      <td>Como nossos pais</td>\n",
       "      <td>BRWMB9705419</td>\n",
       "      <td>27</td>\n",
       "      <td>nao quero falar grande amor coisas aprendi dis...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.337</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>96.559</td>\n",
       "      <td>3Ig3k8enaBZy7cohqfnWVz</td>\n",
       "      <td>280627</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Belchior</td>\n",
       "      <td>https://i.scdn.co/image/22365c7789eb990937bb71...</td>\n",
       "      <td>57</td>\n",
       "      <td>299597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:3AQg8DR76bH9Ko3mZXuSWK</td>\n",
       "      <td>Mosca Na Sopa</td>\n",
       "      <td>BRMCA7300117</td>\n",
       "      <td>45</td>\n",
       "      <td>mosca pousou sopa mosca pintou pra abusar mosc...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>92.022</td>\n",
       "      <td>3AQg8DR76bH9Ko3mZXuSWK</td>\n",
       "      <td>239187</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian psychedelic</td>\n",
       "      <td>Raul Seixas</td>\n",
       "      <td>https://i.scdn.co/image/ad67b61dd80b071a2ac908...</td>\n",
       "      <td>63</td>\n",
       "      <td>829961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           song_sp_uri         song_name  \\\n",
       "0           0  spotify:track:0VUgbCK0k8QWGpLiEV8YYZ            Cálice   \n",
       "1           1  spotify:track:2GAFZG9Z7UGS1iMm4Idrnr    Apesar De Você   \n",
       "2           2  spotify:track:06ND7qqsmIRCuWdQNQIlTE         Roda-Viva   \n",
       "3           3  spotify:track:3Ig3k8enaBZy7cohqfnWVz  Como nossos pais   \n",
       "4           4  spotify:track:3AQg8DR76bH9Ko3mZXuSWK     Mosca Na Sopa   \n",
       "\n",
       "      song_isrc  song_popularity  \\\n",
       "0  BRPGD7800015               50   \n",
       "1  BRPGD7800024               57   \n",
       "2  BRSGL6800006               53   \n",
       "3  BRWMB9705419               27   \n",
       "4  BRMCA7300117               45   \n",
       "\n",
       "                                         song_lyrics    class  danceability  \\\n",
       "0  pai , afasta mim calice pai , afasta mim calic...  Protest         0.596   \n",
       "1  amanha vai outro dia amanha vai outro dia aman...  Protest         0.568   \n",
       "2  dias gente sente partiu morreu gente estancou ...  Protest         0.502   \n",
       "3  nao quero falar grande amor coisas aprendi dis...  Protest         0.463   \n",
       "4  mosca pousou sopa mosca pintou pra abusar mosc...  Protest         0.609   \n",
       "\n",
       "   energy  key         ...           valence    tempo                      id  \\\n",
       "0   0.372    4         ...             0.293  123.125  0VUgbCK0k8QWGpLiEV8YYZ   \n",
       "1   0.574    4         ...             0.680  107.820  2GAFZG9Z7UGS1iMm4Idrnr   \n",
       "2   0.512   10         ...             0.651  133.174  06ND7qqsmIRCuWdQNQIlTE   \n",
       "3   0.337    8         ...             0.269   96.559  3Ig3k8enaBZy7cohqfnWVz   \n",
       "4   0.760    2         ...             0.880   92.022  3AQg8DR76bH9Ko3mZXuSWK   \n",
       "\n",
       "   duration_ms  time_signature          artist_genres    artist_name  \\\n",
       "0       241867               4             bossa nova  Chico Buarque   \n",
       "1       235547               4             bossa nova  Chico Buarque   \n",
       "2       233400               4             bossa nova  Chico Buarque   \n",
       "3       280627               4             bossa nova       Belchior   \n",
       "4       239187               4  brazilian psychedelic    Raul Seixas   \n",
       "\n",
       "                                        artist_photo artist_popularity  \\\n",
       "0  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...                63   \n",
       "1  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...                63   \n",
       "2  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...                63   \n",
       "3  https://i.scdn.co/image/22365c7789eb990937bb71...                57   \n",
       "4  https://i.scdn.co/image/ad67b61dd80b071a2ac908...                63   \n",
       "\n",
       "   artist_sp_followers  \n",
       "0               542214  \n",
       "1               542214  \n",
       "2               542214  \n",
       "3               299597  \n",
       "4               829961  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('brz_dictatorship.csv', encoding='utf-8')\n",
    "df = df.dropna(axis=0)\n",
    "display(df.head())\n",
    "\n",
    "stopwords = open(\"pt_stopwords.txt\").readlines()\n",
    "stopwords = list(map(str.strip, stopwords))\n",
    "\n",
    "df['tempo'] = pd.to_numeric(df['tempo'], downcast=\"float\")\n",
    "df['duration_ms'] = pd.to_numeric(df['duration_ms'], downcast=\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = RSLPStemmer()\n",
    "df['cleaned'] = df['song_lyrics'].astype('str')\n",
    "df['cleaned'] = df['cleaned'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 1391)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=stopwords, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(df['cleaned']).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key]\n",
    "\n",
    "class NumSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                           song_sp_uri         song_name  \\\n",
      "0           0  spotify:track:0VUgbCK0k8QWGpLiEV8YYZ            Cálice   \n",
      "1           1  spotify:track:2GAFZG9Z7UGS1iMm4Idrnr    Apesar De Você   \n",
      "2           2  spotify:track:06ND7qqsmIRCuWdQNQIlTE         Roda-Viva   \n",
      "3           3  spotify:track:3Ig3k8enaBZy7cohqfnWVz  Como nossos pais   \n",
      "4           4  spotify:track:3AQg8DR76bH9Ko3mZXuSWK     Mosca Na Sopa   \n",
      "\n",
      "      song_isrc  song_popularity  \\\n",
      "0  BRPGD7800015               50   \n",
      "1  BRPGD7800024               57   \n",
      "2  BRSGL6800006               53   \n",
      "3  BRWMB9705419               27   \n",
      "4  BRMCA7300117               45   \n",
      "\n",
      "                                         song_lyrics    class  danceability  \\\n",
      "0  pai , afasta mim calice pai , afasta mim calic...  Protest         0.596   \n",
      "1  amanha vai outro dia amanha vai outro dia aman...  Protest         0.568   \n",
      "2  dias gente sente partiu morreu gente estancou ...  Protest         0.502   \n",
      "3  nao quero falar grande amor coisas aprendi dis...  Protest         0.463   \n",
      "4  mosca pousou sopa mosca pintou pra abusar mosc...  Protest         0.609   \n",
      "\n",
      "   energy  key                        ...                               tempo  \\\n",
      "0   0.372    4                        ...                          123.125000   \n",
      "1   0.574    4                        ...                          107.820000   \n",
      "2   0.512   10                        ...                          133.173996   \n",
      "3   0.337    8                        ...                           96.558998   \n",
      "4   0.760    2                        ...                           92.022003   \n",
      "\n",
      "                       id  duration_ms  time_signature          artist_genres  \\\n",
      "0  0VUgbCK0k8QWGpLiEV8YYZ     241867.0               4             bossa nova   \n",
      "1  2GAFZG9Z7UGS1iMm4Idrnr     235547.0               4             bossa nova   \n",
      "2  06ND7qqsmIRCuWdQNQIlTE     233400.0               4             bossa nova   \n",
      "3  3Ig3k8enaBZy7cohqfnWVz     280627.0               4             bossa nova   \n",
      "4  3AQg8DR76bH9Ko3mZXuSWK     239187.0               4  brazilian psychedelic   \n",
      "\n",
      "     artist_name                                       artist_photo  \\\n",
      "0  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "1  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "2  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "3       Belchior  https://i.scdn.co/image/22365c7789eb990937bb71...   \n",
      "4    Raul Seixas  https://i.scdn.co/image/ad67b61dd80b071a2ac908...   \n",
      "\n",
      "   artist_popularity artist_sp_followers  \\\n",
      "0                 63              542214   \n",
      "1                 63              542214   \n",
      "2                 63              542214   \n",
      "3                 57              299597   \n",
      "4                 63              829961   \n",
      "\n",
      "                                             cleaned  \n",
      "0  pai afast mim calic pai afast mim calic pai af...  \n",
      "1  amanh vai outr dia amanh vai outr dia amanh va...  \n",
      "2  dia gent sent part morr gent estanc repent mun...  \n",
      "3  nao quer fal grand am cois aprend disc quer co...  \n",
      "4  mosc pous sop mosc pint pra abus mosc pous sop...  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                  score\n",
      "-------------------  -------\n",
      "bern_nb               0.5862\n",
      "bern_nb_tfidf         0.5862\n",
      "mult_nb               0.6362\n",
      "mult_nb_tfidf         0.5542\n",
      "random_forest         0.6464\n",
      "random_forest_tfidf   0.7487\n",
      "svc                   0.6672\n",
      "svc_tfidf             0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "y = df['class']\n",
    "\n",
    "labels = df['class'].map(lambda x : 1 if x == 'Protest' else 0)\n",
    "\n",
    "\n",
    "# train word to vector on texts \n",
    "model = Word2Vec(X['song_lyrics'], size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}\n",
    "\n",
    "\n",
    "# ('lyrics', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='song_lyrics')),\n",
    "#                 ('tfidf', vectorizer),\n",
    "#             ])),\n",
    "\n",
    "# multiple machine learning models\n",
    "mult_nb = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), \n",
    "                (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                    ])),\n",
    "                    (\"bernoulli nb\", BernoulliNB())])\n",
    "\n",
    "mult_nb_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), \n",
    "                          (\"multinomial nb\", MultinomialNB())])\n",
    "\n",
    "bern_nb_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM \n",
    "svc = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                ])),\n",
    "                (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "svc_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "# Random Forest\n",
    "random_forest_tfidf = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "#             Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "            ])),\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.values())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.sum([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.values())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "    (\"bern_nb\", bern_nb),\n",
    "    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"random_forest\", random_forest),\n",
    "    (\"random_forest_tfidf\", random_forest_tfidf),\n",
    "#     (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]\n",
    "\n",
    "## Comparing different models\n",
    "scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n",
    "                 for name, model in all_models])\n",
    "print(tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Jovem Guarda       0.71      0.91      0.80        22\n",
      "     Protest       0.89      0.67      0.76        24\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        46\n",
      "   macro avg       0.80      0.79      0.78        46\n",
      "weighted avg       0.81      0.78      0.78        46\n",
      "\n",
      "[[20  2]\n",
      " [ 8 16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# this block is to split the dataset into training and testing set \n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "Y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "# with open('RandomForest.pickle', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'trainables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-bf4d2af8be49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KMP_DUPLICATE_LIB_OK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'True'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwv_from_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/pt/pt.bin\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# C bin format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseKeyedVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[0;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattrib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__scipys'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 )\n\u001b[0;32m-> 1422\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36msyn1neg\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msyn1neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn1neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msyn1neg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2Vec' object has no attribute 'trainables'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "target_vocab = list(df['song_lyrics'].str.split(' ', expand=True).stack().unique())\n",
    "vocabulary_size = len(target_vocab)\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['song_lyrics'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['song_lyrics'])\n",
    "\n",
    "maxlen = df['song_lyrics'].str.len().max()\n",
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocabulary_size, 50))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 165 samples, validate on 19 samples\n",
      "Epoch 1/3\n",
      "165/165 [==============================] - 26s 158ms/step - loss: 0.6936 - acc: 0.5394 - val_loss: 1.0468 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "165/165 [==============================] - 19s 117ms/step - loss: 0.6555 - acc: 0.5939 - val_loss: 0.8732 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "165/165 [==============================] - 33s 198ms/step - loss: 0.6197 - acc: 0.6364 - val_loss: 0.7718 - val_acc: 0.1579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a428e3630>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def BinaryClassificationConvModel():\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(Embedding(vocabulary_size, 50, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
    "    model_conv.add(Dropout(0.2))\n",
    "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(LSTM(50))\n",
    "    model_conv.add(Dense(1, activation='sigmoid'))\n",
    "    model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "model_conv = BinaryClassificationConvModel()\n",
    "model_conv.fit(data, np.array(labels), validation_split=0.1, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
