{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "# Import supplementary visualization code visuals.py\n",
    "import visuals as vs\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest.pickle         model.ipynb\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                 model_plot.png\r\n",
      "analysis.Rmd                \u001b[34mmodels\u001b[m\u001b[m\r\n",
      "analysis.pdf                out\r\n",
      "\u001b[34manalysis_files\u001b[m\u001b[m              \u001b[31mplaylist_processor.py\u001b[m\u001b[m\r\n",
      "analysis_final.Rmd          \u001b[34mplots\u001b[m\u001b[m\r\n",
      "brew                        protest.csv\r\n",
      "brz_dictatorship.csv        pt_stopwords.txt\r\n",
      "brz_dictatorship_target.csv sequences.txt\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                        visuals.py\r\n",
      "influence.py                whosampled_clean_songs.csv\r\n",
      "jovem_guarda.csv            whosampled_data.csv\r\n",
      "lstm_char_model.ipynb       whosampled_list.csv\r\n",
      "main.pyc                    whosampled_scraper.py\r\n",
      "model.h5                    wordmodel.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>song_sp_uri</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_isrc</th>\n",
       "      <th>song_popularity</th>\n",
       "      <th>song_lyrics</th>\n",
       "      <th>class</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>id</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_genres</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_photo</th>\n",
       "      <th>artist_popularity</th>\n",
       "      <th>artist_sp_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>spotify:track:4zJnSZJjCmGnkQX1W38ZIl</td>\n",
       "      <td>Calix-Se</td>\n",
       "      <td>US7VG1593526</td>\n",
       "      <td>36</td>\n",
       "      <td>pai sinto falta voce aqui rua campim quanto to...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.744</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812</td>\n",
       "      <td>82.004</td>\n",
       "      <td>4zJnSZJjCmGnkQX1W38ZIl</td>\n",
       "      <td>360751</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "      <td>Trilha Sonora do Gueto</td>\n",
       "      <td>https://i.scdn.co/image/f44f9e10538aa6391688ca...</td>\n",
       "      <td>45</td>\n",
       "      <td>130298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spotify:track:744T5MTpQJhem1FPdKvTQ1</td>\n",
       "      <td>Direita Vou Ver</td>\n",
       "      <td>BXRCL1800064</td>\n",
       "      <td>25</td>\n",
       "      <td>`` continuo sendo socialista , portanto , esqu...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.811</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639</td>\n",
       "      <td>79.934</td>\n",
       "      <td>744T5MTpQJhem1FPdKvTQ1</td>\n",
       "      <td>364504</td>\n",
       "      <td>4</td>\n",
       "      <td>adoracao</td>\n",
       "      <td>Mensageiros da Profecia</td>\n",
       "      <td>https://i.scdn.co/image/688287e9b2eefe63a25912...</td>\n",
       "      <td>35</td>\n",
       "      <td>20698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:6Wt61AZLG0bN2KasopE2sj</td>\n",
       "      <td>Capítulo 4, Versículo 3</td>\n",
       "      <td>US7VG1324929</td>\n",
       "      <td>58</td>\n",
       "      <td>60 % jovens periferia antecedentes criminais j...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.515</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903</td>\n",
       "      <td>87.841</td>\n",
       "      <td>6Wt61AZLG0bN2KasopE2sj</td>\n",
       "      <td>486560</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "      <td>Racionais MC's</td>\n",
       "      <td>https://i.scdn.co/image/0e9f58b86b301af364cc4c...</td>\n",
       "      <td>67</td>\n",
       "      <td>2495926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:4EBu1H5VUbBRXGtARMnkib</td>\n",
       "      <td>Brasil Com \"P\"</td>\n",
       "      <td>US7VG1539057</td>\n",
       "      <td>21</td>\n",
       "      <td>pesquisa publicada prova : preferencialmente p...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.486</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564</td>\n",
       "      <td>57.986</td>\n",
       "      <td>4EBu1H5VUbBRXGtARMnkib</td>\n",
       "      <td>104227</td>\n",
       "      <td>4</td>\n",
       "      <td>brazilian hip hop</td>\n",
       "      <td>GOG</td>\n",
       "      <td>https://i.scdn.co/image/de0d09c17287d9656696bb...</td>\n",
       "      <td>42</td>\n",
       "      <td>47072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>spotify:track:58ZMFOd08nb2WrOoFhI4cY</td>\n",
       "      <td>Filho maravilha</td>\n",
       "      <td>BRWMB9801175</td>\n",
       "      <td>33</td>\n",
       "      <td>novamente chegou inspiracao amor , emocao , ex...</td>\n",
       "      <td>Protest</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.865</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774</td>\n",
       "      <td>136.564</td>\n",
       "      <td>58ZMFOd08nb2WrOoFhI4cY</td>\n",
       "      <td>215693</td>\n",
       "      <td>4</td>\n",
       "      <td>bossa nova</td>\n",
       "      <td>Jorge Ben Jor</td>\n",
       "      <td>https://i.scdn.co/image/a9c6a324c5f4a0f25bc711...</td>\n",
       "      <td>64</td>\n",
       "      <td>368372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           song_sp_uri                song_name  \\\n",
       "1           1  spotify:track:4zJnSZJjCmGnkQX1W38ZIl                 Calix-Se   \n",
       "2           2  spotify:track:744T5MTpQJhem1FPdKvTQ1          Direita Vou Ver   \n",
       "3           3  spotify:track:6Wt61AZLG0bN2KasopE2sj  Capítulo 4, Versículo 3   \n",
       "4           4  spotify:track:4EBu1H5VUbBRXGtARMnkib           Brasil Com \"P\"   \n",
       "5           5  spotify:track:58ZMFOd08nb2WrOoFhI4cY          Filho maravilha   \n",
       "\n",
       "      song_isrc  song_popularity  \\\n",
       "1  US7VG1593526               36   \n",
       "2  BXRCL1800064               25   \n",
       "3  US7VG1324929               58   \n",
       "4  US7VG1539057               21   \n",
       "5  BRWMB9801175               33   \n",
       "\n",
       "                                         song_lyrics    class  danceability  \\\n",
       "1  pai sinto falta voce aqui rua campim quanto to...  Protest         0.760   \n",
       "2  `` continuo sendo socialista , portanto , esqu...  Protest         0.545   \n",
       "3  60 % jovens periferia antecedentes criminais j...  Protest         0.625   \n",
       "4  pesquisa publicada prova : preferencialmente p...  Protest         0.628   \n",
       "5  novamente chegou inspiracao amor , emocao , ex...  Protest         0.561   \n",
       "\n",
       "   energy  key         ...           valence    tempo                      id  \\\n",
       "1   0.744   11         ...             0.812   82.004  4zJnSZJjCmGnkQX1W38ZIl   \n",
       "2   0.811   11         ...             0.639   79.934  744T5MTpQJhem1FPdKvTQ1   \n",
       "3   0.515    8         ...             0.903   87.841  6Wt61AZLG0bN2KasopE2sj   \n",
       "4   0.486    8         ...             0.564   57.986  4EBu1H5VUbBRXGtARMnkib   \n",
       "5   0.865    4         ...             0.774  136.564  58ZMFOd08nb2WrOoFhI4cY   \n",
       "\n",
       "   duration_ms  time_signature      artist_genres              artist_name  \\\n",
       "1       360751               4  brazilian hip hop   Trilha Sonora do Gueto   \n",
       "2       364504               4           adoracao  Mensageiros da Profecia   \n",
       "3       486560               4  brazilian hip hop           Racionais MC's   \n",
       "4       104227               4  brazilian hip hop                      GOG   \n",
       "5       215693               4         bossa nova            Jorge Ben Jor   \n",
       "\n",
       "                                        artist_photo artist_popularity  \\\n",
       "1  https://i.scdn.co/image/f44f9e10538aa6391688ca...                45   \n",
       "2  https://i.scdn.co/image/688287e9b2eefe63a25912...                35   \n",
       "3  https://i.scdn.co/image/0e9f58b86b301af364cc4c...                67   \n",
       "4  https://i.scdn.co/image/de0d09c17287d9656696bb...                42   \n",
       "5  https://i.scdn.co/image/a9c6a324c5f4a0f25bc711...                64   \n",
       "\n",
       "   artist_sp_followers  \n",
       "1               130298  \n",
       "2                20698  \n",
       "3              2495926  \n",
       "4                47072  \n",
       "5               368372  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('brz_dictatorship.csv', encoding='utf-8')\n",
    "df_test = pd.read_csv('whosampled_data.csv', encoding='utf-8').dropna(axis=0)\n",
    "df = df.dropna(axis=0)\n",
    "display(df_test.head())\n",
    "\n",
    "stopwords = open(\"pt_stopwords.txt\").readlines()\n",
    "stopwords = list(map(str.strip, stopwords))\n",
    "\n",
    "df['tempo'] = pd.to_numeric(df['tempo'], downcast=\"float\")\n",
    "df['duration_ms'] = pd.to_numeric(df['duration_ms'], downcast=\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = RSLPStemmer()\n",
    "df['cleaned'] = df['song_lyrics'].astype('str')\n",
    "df['cleaned'] = df['cleaned'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 1391)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=stopwords, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(df['cleaned']).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key]\n",
    "\n",
    "class NumSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        return df[self.key].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                           song_sp_uri         song_name  \\\n",
      "0           0  spotify:track:0VUgbCK0k8QWGpLiEV8YYZ            Cálice   \n",
      "1           1  spotify:track:2GAFZG9Z7UGS1iMm4Idrnr    Apesar De Você   \n",
      "2           2  spotify:track:06ND7qqsmIRCuWdQNQIlTE         Roda-Viva   \n",
      "3           3  spotify:track:3Ig3k8enaBZy7cohqfnWVz  Como nossos pais   \n",
      "4           4  spotify:track:3AQg8DR76bH9Ko3mZXuSWK     Mosca Na Sopa   \n",
      "\n",
      "      song_isrc  song_popularity  \\\n",
      "0  BRPGD7800015               50   \n",
      "1  BRPGD7800024               57   \n",
      "2  BRSGL6800006               53   \n",
      "3  BRWMB9705419               27   \n",
      "4  BRMCA7300117               45   \n",
      "\n",
      "                                         song_lyrics    class  danceability  \\\n",
      "0  pai , afasta mim calice pai , afasta mim calic...  Protest         0.596   \n",
      "1  amanha vai outro dia amanha vai outro dia aman...  Protest         0.568   \n",
      "2  dias gente sente partiu morreu gente estancou ...  Protest         0.502   \n",
      "3  nao quero falar grande amor coisas aprendi dis...  Protest         0.463   \n",
      "4  mosca pousou sopa mosca pintou pra abusar mosc...  Protest         0.609   \n",
      "\n",
      "   energy  key                        ...                               tempo  \\\n",
      "0   0.372    4                        ...                          123.125000   \n",
      "1   0.574    4                        ...                          107.820000   \n",
      "2   0.512   10                        ...                          133.173996   \n",
      "3   0.337    8                        ...                           96.558998   \n",
      "4   0.760    2                        ...                           92.022003   \n",
      "\n",
      "                       id  duration_ms  time_signature          artist_genres  \\\n",
      "0  0VUgbCK0k8QWGpLiEV8YYZ     241867.0               4             bossa nova   \n",
      "1  2GAFZG9Z7UGS1iMm4Idrnr     235547.0               4             bossa nova   \n",
      "2  06ND7qqsmIRCuWdQNQIlTE     233400.0               4             bossa nova   \n",
      "3  3Ig3k8enaBZy7cohqfnWVz     280627.0               4             bossa nova   \n",
      "4  3AQg8DR76bH9Ko3mZXuSWK     239187.0               4  brazilian psychedelic   \n",
      "\n",
      "     artist_name                                       artist_photo  \\\n",
      "0  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "1  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "2  Chico Buarque  https://i.scdn.co/image/c1a6ae9e79561abeb0bd97...   \n",
      "3       Belchior  https://i.scdn.co/image/22365c7789eb990937bb71...   \n",
      "4    Raul Seixas  https://i.scdn.co/image/ad67b61dd80b071a2ac908...   \n",
      "\n",
      "   artist_popularity artist_sp_followers  \\\n",
      "0                 63              542214   \n",
      "1                 63              542214   \n",
      "2                 63              542214   \n",
      "3                 57              299597   \n",
      "4                 63              829961   \n",
      "\n",
      "                                             cleaned  \n",
      "0  pai afast mim calic pai afast mim calic pai af...  \n",
      "1  amanh vai outr dia amanh vai outr dia amanh va...  \n",
      "2  dia gent sent part morr gent estanc repent mun...  \n",
      "3  nao quer fal grand am cois aprend disc quer co...  \n",
      "4  mosc pous sop mosc pint pra abus mosc pous sop...  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                  score\n",
      "-------------------  -------\n",
      "bern_nb               0.5862\n",
      "bern_nb_tfidf         0.5862\n",
      "mult_nb               0.6362\n",
      "mult_nb_tfidf         0.5542\n",
      "random_forest         0.6944\n",
      "random_forest_tfidf   0.7491\n",
      "svc                   0.6672\n",
      "svc_tfidf             0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "y = df['class']\n",
    "\n",
    "labels = df['class'].map(lambda x : 1 if x == 'Protest' else 0)\n",
    "\n",
    "\n",
    "# train word to vector on texts \n",
    "model = Word2Vec(X['song_lyrics'], size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}\n",
    "\n",
    "\n",
    "# ('lyrics', Pipeline([\n",
    "#                 ('selector', ItemSelector(key='song_lyrics')),\n",
    "#                 ('tfidf', vectorizer),\n",
    "#             ])),\n",
    "\n",
    "# multiple machine learning models\n",
    "mult_nb = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), \n",
    "                (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                    ])),\n",
    "                    (\"bernoulli nb\", BernoulliNB())])\n",
    "\n",
    "mult_nb_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), \n",
    "                          (\"multinomial nb\", MultinomialNB())])\n",
    "\n",
    "bern_nb_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM \n",
    "svc = Pipeline([('lyrics', Pipeline([\n",
    "                        ('selector', ItemSelector(key='song_lyrics')),\n",
    "                        (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "                ])),\n",
    "                (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "svc_tfidf = Pipeline([('lyrics', Pipeline([\n",
    "                    ('selector', ItemSelector(key='song_lyrics')),\n",
    "                    (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)),\n",
    "                    ])), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "# Random Forest\n",
    "random_forest_tfidf = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "#             Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\n",
    "            ])),\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.values())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.sum([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.values())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "    (\"bern_nb\", bern_nb),\n",
    "    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"random_forest\", random_forest),\n",
    "    (\"random_forest_tfidf\", random_forest_tfidf),\n",
    "#     (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]\n",
    "\n",
    "## Comparing different models\n",
    "scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n",
    "                 for name, model in all_models])\n",
    "print(tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Jovem Guarda       0.62      0.89      0.73         9\n",
      "     Protest       0.83      0.50      0.62        10\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        19\n",
      "   macro avg       0.72      0.69      0.68        19\n",
      "weighted avg       0.73      0.68      0.67        19\n",
      "\n",
      "[[8 1]\n",
      " [5 5]]\n",
      "Feature ranking:\n",
      "1. feature 61 (0.035229)\n",
      "2. feature 1302 (0.033080)\n",
      "3. feature 198 (0.021962)\n",
      "4. feature 947 (0.020056)\n",
      "5. feature 1186 (0.015947)\n",
      "6. feature 339 (0.015670)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# this block is to split the dataset into training and testing set \n",
    "X = df[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "Y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('lyrics', Pipeline([\n",
    "                ('selector', ItemSelector(key='song_lyrics')),\n",
    "                ('tfidf', vectorizer),\n",
    "            ])),\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('duration', Pipeline([\n",
    "                ('selector', NumSelector(key='duration_ms')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "            ('tempo', Pipeline([\n",
    "                ('selector', NumSelector(key='tempo')),\n",
    "                ('minxMax', StandardScaler()),\n",
    "            ])),\n",
    "        ]\n",
    "    )),\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# fitting our model and save it in a pickle for later use\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "# with open('RandomForest.pickle', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))\n",
    "\n",
    "forest = pipeline.steps[1][1]\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "                           song_name              artist_name  \\\n",
      "1                           Calix-Se   Trilha Sonora do Gueto   \n",
      "2                    Direita Vou Ver  Mensageiros da Profecia   \n",
      "3            Capítulo 4, Versículo 3           Racionais MC's   \n",
      "4                     Brasil Com \"P\"                      GOG   \n",
      "5                    Filho maravilha            Jorge Ben Jor   \n",
      "6        Flor da Pele / Vapor Barato             Zeca Baleiro   \n",
      "8                       Rio 40 Graus           Fernanda Abreu   \n",
      "9                      Monte Castelo            Legião Urbana   \n",
      "12              Primavera Nos Dentes             Cidade Negra   \n",
      "13  Senhor delegado / Eu não aguento                    Titãs   \n",
      "\n",
      "                                         artist_photo  \n",
      "1   https://i.scdn.co/image/f44f9e10538aa6391688ca...  \n",
      "2   https://i.scdn.co/image/688287e9b2eefe63a25912...  \n",
      "3   https://i.scdn.co/image/0e9f58b86b301af364cc4c...  \n",
      "4   https://i.scdn.co/image/de0d09c17287d9656696bb...  \n",
      "5   https://i.scdn.co/image/a9c6a324c5f4a0f25bc711...  \n",
      "6   https://i.scdn.co/image/d3ce35b9e2a3ef49db1657...  \n",
      "8   https://i.scdn.co/image/4ee0464154912f0d2a42b7...  \n",
      "9   https://i.scdn.co/image/cd410bc7c6e3591f65d9c9...  \n",
      "12  https://i.scdn.co/image/72be57bd6f7bf2d6b75bd1...  \n",
      "13  https://i.scdn.co/image/06d1db83431c0424d4ef18...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsaruhashi/anaconda2/envs/py37/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Jovem Guarda', 'Protest', 'Jovem Guarda', 'Protest',\n",
       "       'Jovem Guarda', 'Protest', 'Protest', 'Protest', 'Protest',\n",
       "       'Jovem Guarda'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_test[['song_lyrics', 'valence', 'duration_ms', 'danceability', 'acousticness', 'tempo']]\n",
    "print(len(df_test))\n",
    "print(df_test[['song_name', 'artist_name', 'artist_photo']])\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "target_vocab = list(df['song_lyrics'].str.split(' ', expand=True).stack().unique())\n",
    "vocabulary_size = len(target_vocab)\n",
    "\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(df['song_lyrics'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['song_lyrics'])\n",
    "\n",
    "maxlen = df['song_lyrics'].str.len().max()\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 165 samples, validate on 19 samples\n",
      "Epoch 1/50\n",
      "165/165 [==============================] - 8s 49ms/step - loss: 0.6934 - acc: 0.4909 - val_loss: 0.6870 - val_acc: 0.5789\n",
      "Epoch 2/50\n",
      "165/165 [==============================] - 5s 33ms/step - loss: 0.6899 - acc: 0.5273 - val_loss: 0.6847 - val_acc: 0.5789\n",
      "Epoch 3/50\n",
      "165/165 [==============================] - 5s 33ms/step - loss: 0.6879 - acc: 0.5273 - val_loss: 0.6821 - val_acc: 0.5789\n",
      "Epoch 4/50\n",
      "165/165 [==============================] - 5s 33ms/step - loss: 0.6865 - acc: 0.5273 - val_loss: 0.6815 - val_acc: 0.5789\n",
      "Epoch 5/50\n",
      "165/165 [==============================] - 5s 33ms/step - loss: 0.6830 - acc: 0.5273 - val_loss: 0.6803 - val_acc: 0.5789\n",
      "Epoch 6/50\n",
      "165/165 [==============================] - 9s 57ms/step - loss: 0.6797 - acc: 0.5273 - val_loss: 0.6802 - val_acc: 0.5789\n",
      "Epoch 7/50\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 0.6714 - acc: 0.5273 - val_loss: 0.6807 - val_acc: 0.5789\n",
      "Epoch 8/50\n",
      "165/165 [==============================] - 10s 58ms/step - loss: 0.6596 - acc: 0.5758 - val_loss: 0.6837 - val_acc: 0.4737\n",
      "Epoch 9/50\n",
      "165/165 [==============================] - 9s 57ms/step - loss: 0.6380 - acc: 0.8000 - val_loss: 0.6777 - val_acc: 0.5263\n",
      "Epoch 10/50\n",
      "165/165 [==============================] - 6s 37ms/step - loss: 0.5727 - acc: 0.7333 - val_loss: 1.0652 - val_acc: 0.5789\n",
      "Epoch 11/50\n",
      "165/165 [==============================] - 10s 62ms/step - loss: 0.6365 - acc: 0.7515 - val_loss: 2.0598 - val_acc: 0.5789\n",
      "Epoch 12/50\n",
      "165/165 [==============================] - 6s 38ms/step - loss: 2.0037 - acc: 0.5273 - val_loss: 1.0994 - val_acc: 0.5789\n",
      "Epoch 13/50\n",
      "165/165 [==============================] - 11s 66ms/step - loss: 0.7310 - acc: 0.5939 - val_loss: 0.8263 - val_acc: 0.4211\n",
      "Epoch 14/50\n",
      "165/165 [==============================] - 6s 37ms/step - loss: 0.7091 - acc: 0.4788 - val_loss: 0.7633 - val_acc: 0.4211\n",
      "Epoch 15/50\n",
      "165/165 [==============================] - 6s 38ms/step - loss: 0.6577 - acc: 0.4909 - val_loss: 0.7223 - val_acc: 0.4211\n",
      "Epoch 16/50\n",
      "165/165 [==============================] - 9s 55ms/step - loss: 0.6272 - acc: 0.6606 - val_loss: 0.6979 - val_acc: 0.6316\n",
      "Epoch 17/50\n",
      "165/165 [==============================] - 5s 32ms/step - loss: 0.6156 - acc: 0.8485 - val_loss: 0.6881 - val_acc: 0.5263\n",
      "Epoch 18/50\n",
      "165/165 [==============================] - 10s 62ms/step - loss: 0.6051 - acc: 0.8485 - val_loss: 0.6849 - val_acc: 0.5263\n",
      "Epoch 19/50\n",
      "165/165 [==============================] - 7s 41ms/step - loss: 0.5932 - acc: 0.7818 - val_loss: 0.6843 - val_acc: 0.5263\n",
      "Epoch 20/50\n",
      "165/165 [==============================] - 8s 50ms/step - loss: 0.5814 - acc: 0.7697 - val_loss: 0.6855 - val_acc: 0.5263\n",
      "Epoch 21/50\n",
      "165/165 [==============================] - 9s 56ms/step - loss: 0.5688 - acc: 0.8242 - val_loss: 0.6881 - val_acc: 0.5263\n",
      "Epoch 22/50\n",
      "165/165 [==============================] - 6s 38ms/step - loss: 0.5515 - acc: 0.8303 - val_loss: 0.6906 - val_acc: 0.5263\n",
      "Epoch 23/50\n",
      "165/165 [==============================] - 5s 33ms/step - loss: 0.5272 - acc: 0.8545 - val_loss: 0.6971 - val_acc: 0.4737\n",
      "Epoch 24/50\n",
      "165/165 [==============================] - 5s 32ms/step - loss: 0.5027 - acc: 0.8545 - val_loss: 0.7025 - val_acc: 0.5263\n",
      "Epoch 25/50\n",
      "165/165 [==============================] - 7s 40ms/step - loss: 0.4717 - acc: 0.8606 - val_loss: 0.7209 - val_acc: 0.5263\n",
      "Epoch 26/50\n",
      "165/165 [==============================] - 6s 33ms/step - loss: 0.4432 - acc: 0.8667 - val_loss: 0.7935 - val_acc: 0.5789\n",
      "Epoch 27/50\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 0.4636 - acc: 0.7818 - val_loss: 0.7704 - val_acc: 0.6842\n",
      "Epoch 28/50\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 0.4371 - acc: 0.7818 - val_loss: 0.8167 - val_acc: 0.5263\n",
      "Epoch 29/50\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 0.4050 - acc: 0.8667 - val_loss: 0.8108 - val_acc: 0.5263\n",
      "Epoch 30/50\n",
      "165/165 [==============================] - 6s 33ms/step - loss: 0.3577 - acc: 0.8909 - val_loss: 0.8012 - val_acc: 0.5263\n",
      "Epoch 31/50\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 0.3392 - acc: 0.8970 - val_loss: 0.8898 - val_acc: 0.5789\n",
      "Epoch 32/50\n",
      "165/165 [==============================] - 5s 33ms/step - loss: 0.3409 - acc: 0.8788 - val_loss: 0.9480 - val_acc: 0.5263\n",
      "Epoch 33/50\n",
      "165/165 [==============================] - 6s 35ms/step - loss: 0.2857 - acc: 0.9152 - val_loss: 1.0111 - val_acc: 0.5263\n",
      "Epoch 34/50\n",
      "165/165 [==============================] - 6s 38ms/step - loss: 0.2845 - acc: 0.8848 - val_loss: 1.0308 - val_acc: 0.5263\n",
      "Epoch 35/50\n",
      "165/165 [==============================] - 6s 34ms/step - loss: 0.2478 - acc: 0.9152 - val_loss: 1.0397 - val_acc: 0.4737\n",
      "Epoch 36/50\n",
      " 64/165 [==========>...................] - ETA: 3s - loss: 0.2972 - acc: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cfdb9c1e2920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationConvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py37/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def BinaryClassificationConvModel():\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(Embedding(vocabulary_size, 50, input_length=maxlen, trainable=False))\n",
    "    model_conv.add(Dropout(0.2))\n",
    "    model_conv.add(Conv1D(64, 5, activation='relu'))\n",
    "    model_conv.add(MaxPooling1D(pool_size=4))\n",
    "    model_conv.add(LSTM(50))\n",
    "    model_conv.add(Dense(1, activation='sigmoid'))\n",
    "    model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "    return model_conv\n",
    "\n",
    "model_conv = BinaryClassificationConvModel()\n",
    "model_conv.fit(X_train, np.array(y_train), epochs = 50,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
